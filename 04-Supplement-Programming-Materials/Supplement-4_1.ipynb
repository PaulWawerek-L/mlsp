{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Supplement 4: Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.naive_bayes import GaussianNB"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.1 Programming Task: Gaussian Naive-Bayes Classifier\n",
        "The Iris dataset, containing measurements of the flower parts obtained from 3 different species of the Iris plant, is provided in the file __iris.csv__. The first four columns of the dataset contain the measurement values representing input features for the model and the last column contains class labels of the plant species: Iris-setosa, Iris-versicolor, and Iris-virginica.\n",
        "The goal of this task is to implement a Gaussian Naive-Bayes classifier for the Iris dataset.\n",
        "\n",
        "i\\. What are the assumptions on the dataset required for the Gaussian Naive-Bayes model?  \n",
        "    - Data following a Gaussian pdf and iid data\n",
        "\n",
        "ii\\. Split the dataset into train and test by the 80:20 ratio.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train set size: 120\n",
            "Test set size: 30\n"
          ]
        }
      ],
      "source": [
        "dataset = pd.read_csv('iris.csv')\n",
        "# Class labels present in this dataset\n",
        "class_labels = list(dataset['Species'].unique())\n",
        "input_features = list(dataset.columns[:-1])\n",
        "# Shuffle the dataset\n",
        "dataset = dataset.sample(frac=1).reset_index(drop=True)\n",
        "# Split the dataset\n",
        "trainset_size = int(len(dataset) * 0.8)\n",
        "trainset = dataset[:trainset_size]\n",
        "testset = dataset[trainset_size:]\n",
        "print('Train set size:', len(trainset))\n",
        "print('Test set size:', len(testset))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "iii\\. Estimate the parameters of the Gaussian Naive-Bayes classifier using the train set.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def gaussian_probability_function(x, mean, std):\n",
        "    arg = -0.5 * ((x - mean) / std)**2\n",
        "    prob = 1 / (std * (np.sqrt(2*np.pi))) * np.exp(arg)\n",
        "    return prob\n",
        "\n",
        "def get_posterior(test_sample, class_name):\n",
        "    # Get features from test sample\n",
        "    test_sepal_l = test_sample['SepalLengthCm']\n",
        "    test_sepal_w = test_sample['SepalWidthCm']\n",
        "    test_petal_l = test_sample['PetalLengthCm']\n",
        "    test_petal_w = test_sample['PetalWidthCm']\n",
        "    # Get train samples relevant to class setosa\n",
        "    trainset_given_class = trainset[trainset['Species']==class_name]\n",
        "    # Get prior\n",
        "    prior = len(trainset_given_class) / len(trainset)\n",
        "    # Get mean and std for each feature in trainset\n",
        "    mean_given_class = trainset_given_class[input_features].mean()\n",
        "    std_given_class = trainset_given_class[input_features].std()\n",
        "    # Model p( feature | class) for each feature as a gaussian\n",
        "    prob_sepal_l_given_class = gaussian_probability_function(test_sepal_l,\n",
        "                                    mean_given_class['SepalLengthCm'], std_given_class['SepalLengthCm'])\n",
        "    prob_sepal_w_given_class = gaussian_probability_function(test_sepal_w,\n",
        "                                    mean_given_class['SepalWidthCm'], std_given_class['SepalWidthCm'])\n",
        "    prob_petal_l_given_class = gaussian_probability_function(test_petal_l,\n",
        "                                    mean_given_class['PetalLengthCm'], std_given_class['PetalLengthCm'])\n",
        "    prob_petal_w_given_class = gaussian_probability_function(test_petal_w,\n",
        "                                    mean_given_class['PetalWidthCm'], std_given_class['PetalWidthCm'])\n",
        "    # Assuming features are independent\n",
        "    posterior_class = prob_sepal_l_given_class * prob_sepal_w_given_class * \\\n",
        "                        prob_petal_l_given_class * prob_petal_w_given_class * prior\n",
        "    return posterior_class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "iv\\. Using the learned parameters, predict the classes for the samples in the test set.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "posterior_setosa = get_posterior(testset, class_name='Iris-setosa')\n",
        "posterior_versicolor = get_posterior(testset, class_name='Iris-versicolor')\n",
        "posterior_virginica = get_posterior(testset, class_name='Iris-virginica')\n",
        "\n",
        "posterior = pd.concat((posterior_setosa, posterior_versicolor, posterior_virginica), axis=1)\n",
        "posterior.columns = class_labels\n",
        "predicted_labels = posterior.idxmax(axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "What is the accuracy of the model on the test set?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "29 out of 30 correct prediction\n",
            "Accuracy: 0.9666666666666667\n",
            "Accuracy sklearn GaussianNB: 0.9666666666666667\n"
          ]
        }
      ],
      "source": [
        "ground_truth = testset['Species']\n",
        "correct_predictions = np.sum([predicted_labels == ground_truth])\n",
        "print(f'{correct_predictions} out of {len(testset)} correct prediction')\n",
        "accuracy = correct_predictions/len(testset)\n",
        "print('Accuracy:', accuracy)\n",
        "# same with sklearn.naive_bayes.GaussianNB\n",
        "model = GaussianNB()\n",
        "model.fit(trainset[input_features], trainset['Species'])\n",
        "print('Accuracy sklearn GaussianNB:', model.score(testset[input_features], testset['Species']))"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3.9.15 ('mlsp')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15 (main, Nov  4 2022, 16:13:54) \n[GCC 11.2.0]"
    },
    "nteract": {
      "version": "0.15.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "d57cc28cc149ef2e4b19b6e5a0bff660d006ed5f61e0dd4a41526f0330d7cac2"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
